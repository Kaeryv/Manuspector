{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from toolkit.dataset import load_spectral_data, dataset_dict_to_dense, normalize_spectra\n",
    "import torch\n",
    "def torchify(X, dtype=torch.float):\n",
    "    return torch.from_numpy(X).type(dtype)\n",
    "from scipy.signal import savgol_filter\n",
    "import numpy as np\n",
    "dataset_dict = load_spectral_data([\n",
    "    \"../raw_data/DataDavid/UVVIS/*.asc\",\n",
    "    \"../raw_data/DataHenry23/Perkin/New_*/*.asc\",\n",
    "    \"../raw_data/DataJulie/07_09_spectro/**/*.asc\",\n",
    "    \"../raw_data/DataJulie/14_09_2023/*.asc\",\n",
    "    \"../raw_data/DataJulie/11_09_2023/*.asc\",\n",
    "    \"../raw_data/DataJulie/14_09_2023_histo/*.asc\",\n",
    "    \"../raw_data/DataJulie/historique/*.asc\",\n",
    "], verbose=True)\n",
    "wavelength = np.flipud(np.linspace(250, 2500, 226))\n",
    "wl_mask = wavelength <= 2300\n",
    "\n",
    "X, Y = dataset_dict_to_dense(dataset_dict)\n",
    "X = savgol_filter(X, 11, 2, axis=-1)\n",
    "Xtot = X[:, wl_mask].copy()\n",
    "Ytot = Y.copy().astype(np.int32)\n",
    "#X = normalize_spectra(X)\n",
    "valid_mask = np.logical_or(Y[:, 0] == 13, Y[:, 0] == 12)\n",
    "dsmean = X[:, wl_mask].mean(axis=0)\n",
    "dsstd = X[:,wl_mask].std(axis=0) * 2\n",
    "Xtot = (Xtot-dsmean) / dsstd\n",
    "\n",
    "\n",
    "Xv = X[valid_mask]\n",
    "Yv = Y[valid_mask]\n",
    "X = X[~valid_mask]\n",
    "Y = Y[~valid_mask]\n",
    "\n",
    "wavelength = wavelength[wl_mask]\n",
    "\n",
    "X = X[:, wl_mask]\n",
    "X = X[Y[:,5]< 5,:]\n",
    "Y = Y[Y[:,5]< 5,:].astype(np.int32)\n",
    "\n",
    "print(np.count_nonzero(Y[:, 1] == 0))\n",
    "print(np.count_nonzero(Y[:, 1] == 1))\n",
    "print(np.count_nonzero(Y[:, 1] == 2))\n",
    "\n",
    "Xv = Xv[:, wl_mask]\n",
    "Xv = Xv[Yv[:,5]< 4,:]\n",
    "Yv = Yv[Yv[:,5]< 4,:].astype(np.int32)\n",
    "\n",
    "labels = Y[:, 1]\n",
    "labels_v = Yv[:, 1]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch\n",
    "\n",
    "Xs = (X - dsmean) / dsstd\n",
    "Xsv = (Xv-dsmean) / dsstd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = list()\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "for i in range(10):\n",
    "    model = GradientBoostingClassifier()\n",
    "    model.fit(Xs, Y[:, 1])\n",
    "    preds = model.predict(Xsv) \n",
    "    accs.append(np.count_nonzero(preds == labels_v) / len(preds))\n",
    "print(np.min(accs), np.max(accs), np.mean(accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_accuracies = list()\n",
    "for i in range(2, 110):#15\n",
    "    model = KNeighborsClassifier(i)\n",
    "    model.fit(Xs, Y[:, 1])\n",
    "    preds = model.predict(Xsv) \n",
    "    acc = np.count_nonzero(preds == labels_v) / len(preds)\n",
    "    knn_accuracies.append(acc)\n",
    "print(np.argsort(knn_accuracies)[::-1])\n",
    "print(\"KNN\", np.min(knn_accuracies), np.max(knn_accuracies), np.mean(knn_accuracies))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "model = KNeighborsClassifier(31)\n",
    "model.fit(Xs, Y[:, 1])\n",
    "explainer = shap.KernelExplainer(model.predict_proba, Xs)\n",
    "shap_values = explainer.shap_values(Xsv[0])\n",
    "print(shap_values[0].shape)\n",
    "x = np.arange(len(shap_values[0]))\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3)\n",
    "ax1.scatter(x, shap_values[0], c=Xsv[0], cmap=\"RdBu\")\n",
    "ax2.scatter(x, shap_values[1], c=Xsv[0], cmap=\"RdBu\")\n",
    "ax3.scatter(x, shap_values[2], c=Xsv[0], cmap=\"RdBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hybris.optim import ParticleSwarm\n",
    "from keever.runners import generate_job\n",
    "import torch\n",
    "param_names = [\"lr\", \"width\", \"offset\", \"wd\", \"rho\", \"complexity\", \"do\"]\n",
    "bounds = np.asarray([ (1e-5, 1e-4),  (24, 48), (0, 64), (1e-3, 5e-2), (0, 1), (2, 12), (0.0, 0.8)])\n",
    "typefuns = [ float, int, int, float, float, int, float]\n",
    "opt = ParticleSwarm(30, [len(bounds), 0], max_fevals=3000)\n",
    "opt.vmin = bounds[:, 0]\n",
    "opt.vmax = bounds[:, 1]\n",
    "opt.reset(42)\n",
    "seeds = 5\n",
    "bests = list()\n",
    "while not opt.stop():\n",
    "    x = opt.ask()\n",
    "    y = list()\n",
    "    for indiv in x:\n",
    "        fit = []\n",
    "        for i in range(seeds):\n",
    "            generate_job(open(\"../hylaunch.proto.sh\").read(), {key: typefun(value) for key, value, typefun in zip(param_names, indiv, typefuns)}, launch =True, shell=\"bash\")\n",
    "            fit.append(np.max(torch.load(\"../tmp/res.pkl\")[\"accs\"]))\n",
    "\n",
    "        y.append(-np.median(fit))\n",
    "    opt.tell(np.asarray(y))\n",
    "    print(\"CUR BEST\", x[np.argmin(y)], np.min(y))\n",
    "    bests.append((x[np.argmin(y)].copy(), np.min(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(bests))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.67756256e-05 3.44486545e+01 3.73375898e+01 1.83155826e-02\n",
      " 1.09753211e-01 1.06053558e+01 1.26643422e-01]\n",
      "[5.91085456e-05 2.88995865e+01 4.03474348e+01 2.71714218e-02\n",
      " 3.48593053e-01 1.10406569e+01 4.62530883e-01]\n",
      "[7.23783389e-05 3.37002482e+01 4.03633932e+01 4.58072304e-02\n",
      " 0.00000000e+00 6.18058487e+00 7.38579799e-01]\n",
      "[6.51011572e-05 2.67967569e+01 6.40000000e+01 4.07580434e-03\n",
      " 1.98625975e-01 1.20000000e+01 8.00000000e-01]\n",
      "[4.74945910e-05 3.18587437e+01 3.77105239e+01 4.16849855e-02\n",
      " 6.27147146e-01 9.44214059e+00 4.67817484e-01]\n",
      "[4.45592263e-05 2.56836894e+01 6.24588013e+01 5.09426220e-03\n",
      " 4.00000000e-01 1.20000000e+01 8.00000000e-01]\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    print(bests[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
